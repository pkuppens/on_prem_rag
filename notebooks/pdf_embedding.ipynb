{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PDF Embedding Exploration\n",
    "\n",
    "Use different parameter sets to create and query embeddings from a single PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import setup_notebook  # This fixes the path for imports\n",
    "from rag_pipeline.config.parameter_sets import get_param_set\n",
    "from rag_pipeline.core.embeddings import chunk_pdf, embed_chunks, query_embeddings\n",
    "from rag_pipeline.utils.directory_utils import get_project_root, get_test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the chunk text at 100 characters for better readability\n",
    "def line_wrap_chunk(chunk):\n",
    "    return textwrap.fill(chunk, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use absolute paths based on project root\n",
    "root = get_project_root()\n",
    "test_data = get_test_data_dir()\n",
    "\n",
    "param_name = \"fast\"  # options: fast, context_rich, precise, etc.\n",
    "params = get_param_set(param_name)\n",
    "\n",
    "pdf = test_data / \"2303.18223v16.pdf\"\n",
    "\n",
    "persist = root / \"data\" / f\"{param_name}_chroma\"\n",
    "\n",
    "# Ensure persist directory exists\n",
    "persist.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Processing PDF: {pdf.name}\")\n",
    "print(f\"Using parameters: {param_name}\")\n",
    "print(f\"Chunk size: {params.chunking.chunk_size}, Overlap: {params.chunking.chunk_overlap}\")\n",
    "\n",
    "# Step 1: Check if embeddings already exist\n",
    "if (persist / \"chroma.sqlite3\").exists():\n",
    "    print(f\"Embeddings already exist in {persist}, skipping processing.\")\n",
    "else:\n",
    "    # Step 2: Chunk the PDF first\n",
    "    print(\"Step 1: Chunking PDF...\")\n",
    "    chunking_result = chunk_pdf(\n",
    "        pdf,\n",
    "        chunk_size=params.chunking.chunk_size,\n",
    "        chunk_overlap=params.chunking.chunk_overlap,\n",
    "        max_pages=None,  # Process all pages (144)\n",
    "    )\n",
    "\n",
    "    print(f\"Chunking completed:\")\n",
    "    print(f\"  - File: {chunking_result.file_name}\")\n",
    "    print(f\"  - Pages: {chunking_result.num_pages}\")\n",
    "    print(f\"  - File size: {chunking_result.file_size:,} bytes\")\n",
    "    print(f\"  - Chunks created: {chunking_result.chunk_count}\")\n",
    "\n",
    "    # Step 3: Generate and store embeddings\n",
    "    print(\"\\nStep 2: Generating embeddings...\")\n",
    "    chunks, records = embed_chunks(\n",
    "        chunking_result,\n",
    "        params.embedding.model_name,\n",
    "        persist_dir=str(persist),\n",
    "        deduplicate=True,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nProcessing completed:\")\n",
    "    print(f\"  - Total chunks processed: {chunks}\")\n",
    "    print(f\"  - Records stored in database: {records}\")\n",
    "    print(f\"  - Deduplication removed: {chunks - records} duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all PDF files in the test_data directory\n",
    "pdf_files = glob.glob(str(test_data / \"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    pdf_file = Path(pdf_path)\n",
    "    print(f\"Processing: {pdf_file.name}\")\n",
    "\n",
    "    # Skip if already processed (check if embeddings exist)\n",
    "    persist_subdir = persist / pdf_file.stem\n",
    "    persist_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if (persist_subdir / \"chroma.sqlite3\").exists():\n",
    "        print(f\"  Skipping {pdf_file.name} - embeddings already exist\")\n",
    "        continue\n",
    "\n",
    "    # Process the PDF\n",
    "    chunking_result = chunk_pdf(\n",
    "        pdf_file,\n",
    "        chunk_size=params.chunking.chunk_size,\n",
    "        chunk_overlap=params.chunking.chunk_overlap,\n",
    "        max_pages=None,  # Process all pages\n",
    "    )\n",
    "\n",
    "    embed_chunks(\n",
    "        chunking_result,\n",
    "        params.embedding.model_name,\n",
    "        persist_dir=str(persist_subdir),\n",
    "        deduplicate=True,\n",
    "    )\n",
    "\n",
    "print(\"All PDF files processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Query embeddings and get results with similarity scores\n",
    "query_text = \"LLM for Healthcare\"\n",
    "print(f\"Querying embeddings for: '{query_text}'\")\n",
    "\n",
    "results = query_embeddings(query_text, params.embedding.model_name, persist_dir=persist)\n",
    "\n",
    "print(f\"\\nQuery Results:\")\n",
    "print(f\"Found {len(results['all_results'])} results\")\n",
    "\n",
    "if results[\"all_results\"]:\n",
    "    print(f\"\\nTop result (similarity: {results['all_results'][0]['similarity_score']:.4f}):\")\n",
    "    chunk = results[\"all_results\"][0][\"text\"]\n",
    "\n",
    "    print(f\"Text preview:\\n{line_wrap_chunk(chunk)}\")\n",
    "\n",
    "    print(f\"\\nDetailed results:\")\n",
    "    for i, result in enumerate(results[\"all_results\"]):\n",
    "        print(f\"\\nResult {i + 1}:\")\n",
    "        print(f\"  Document: {result['document_name']}\")\n",
    "        print(f\"  Chunk: {result['chunk_index']} (ID: {result['document_id']})\")\n",
    "        print(f\"  Page: {result.get('page_number', 'unknown')}\")\n",
    "        print(f\"  Record ID: {result['record_id']}\")\n",
    "        print(f\"  Similarity score: {result['similarity_score']:.4f}\")\n",
    "        print(f\"  Text chunk: {result['text'][:200]}...\")\n",
    "else:\n",
    "    print(\"No results found for the query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query with unrelated topic to test similarity score range\n",
    "test_query_high = \"Multimodal Large Language Model\"\n",
    "test_query_low = \"Oceanography\"\n",
    "\n",
    "print(f\"\\nTesting similarity score range with both high and low related query: '{test_query_high}' and '{test_query_low}'\")\n",
    "\n",
    "test_results_high = query_embeddings(test_query_high, params.embedding.model_name, persist_dir=persist)\n",
    "test_results_low = query_embeddings(test_query_low, params.embedding.model_name, persist_dir=persist)\n",
    "\n",
    "if test_results_high[\"all_results\"]:\n",
    "    highest_score_high = max(result[\"similarity_score\"] for result in test_results_high[\"all_results\"])\n",
    "    print(f\"\\nHighest similarity score for high related query: {highest_score_high:.4f}\")\n",
    "    print(\"\\nThis helps determine if similarity scores are relative or absolute:\")\n",
    "    print(\"- If scores are relative, they will be high for any query\")\n",
    "    print(\"- If scores are absolute, unrelated queries should have lower scores\")\n",
    "else:\n",
    "    print(\"No results found for the test query.\")\n",
    "\n",
    "if test_results_low[\"all_results\"]:\n",
    "    highest_score_low = max(result[\"similarity_score\"] for result in test_results_low[\"all_results\"])\n",
    "    print(f\"\\nHighest similarity score for low related query: {highest_score_low:.4f}\")\n",
    "else:\n",
    "    print(\"No results found for the test query.\")\n",
    "\n",
    "assert highest_score_high > highest_score_low, (\n",
    "    \"The highest similarity score for the high related query should be higher than the highest similarity score for the low related query\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the best match content for both queries\n",
    "print(\"\\nBest match for high related query:\")\n",
    "if test_results_high[\"all_results\"]:\n",
    "    best_match_high = test_results_high[\"all_results\"][0]\n",
    "    print(f\"Document: {best_match_high['document_name']}\")\n",
    "    print(f\"Page: {best_match_high.get('page_number', 'unknown')}\")\n",
    "    print(f\"Similarity score: {best_match_high['similarity_score']:.4f}\")\n",
    "    print(f\"Content:\\n{best_match_high['text']}\\n\")\n",
    "\n",
    "print(\"\\nBest match for low related query:\")\n",
    "if test_results_low[\"all_results\"]:\n",
    "    best_match_low = test_results_low[\"all_results\"][0]\n",
    "    print(f\"Document: {best_match_low['document_name']}\")\n",
    "    print(f\"Page: {best_match_low.get('page_number', 'unknown')}\")\n",
    "    print(f\"Similarity score: {best_match_low['similarity_score']:.4f}\")\n",
    "    print(f\"Content:\\n{best_match_low['text']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
