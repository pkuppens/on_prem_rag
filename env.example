# Environment Variables for on_prem_rag
# Copy this file to .env and fill in your actual values.
# Docker Compose loads .env automatically for port overrides and other settings.

# =============================================================================
# DOCKER COMPOSE PORT CONFIGURATION (override to avoid conflicts)
# =============================================================================
# Set these when default ports conflict with other services (e.g. Ollama, Chroma).
# See docs/PORTS.md and docs/TEST_DOCKER.md for port config and conflict resolution.

# BACKEND_PORT=9000
# AUTH_PORT=9100
# CHROMA_HOST_PORT=9200
# OLLAMA_HOST_PORT=11434
# FRONTEND_PORT=5173

# =============================================================================
# GOOGLE OAUTH2 CONFIGURATION
# =============================================================================
# Get these from Google Cloud Console (https://console.cloud.google.com/):
# 1. Create/select a project
# 2. Go to "APIs & Services" > "Credentials"
# 3. Click "Create Credentials" > "OAuth 2.0 Client IDs"
# 4. Set application type to "Web application"
# 5. Add redirect URI: http://localhost:8001/oauth/google/callback

# Google OAuth2 Client ID - Public identifier for your application
GOOGLE_CLIENT_ID=

# Google OAuth2 Client Secret - Secret key for your application (keep private!)
GOOGLE_CLIENT_SECRET=

# =============================================================================
# MICROSOFT/AZURE AD OAUTH2 CONFIGURATION
# =============================================================================
# Get these from Azure Portal (https://portal.azure.com/):
# 1. Go to "Azure Active Directory" > "App registrations"
# 2. Click "New registration"
# 3. Set redirect URI: http://localhost:8001/oauth/outlook/callback
# 4. Go to "Certificates & secrets" to create client secret

# Microsoft/Azure AD Application Client ID - Found in app registration overview
MICROSOFT_CLIENT_ID=

# Microsoft/Azure AD Client Secret - Create in "Certificates & secrets" section
MICROSOFT_CLIENT_SECRET=

# Microsoft/Azure AD Tenant ID - Use "common" for multi-tenant, or your specific tenant ID
MICROSOFT_TENANT_ID=common

# =============================================================================
# SESSION AND SECURITY CONFIGURATION
# =============================================================================

# Session Secret Key - Random string used for session encryption and signing
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SESSION_SECRET_KEY=

# =============================================================================
# DEBUG AND DEVELOPMENT SETTINGS
# =============================================================================

# Server Debug Mode - Set to True for detailed error messages in development
# Set to False in production to hide sensitive error details
SERVER_DEBUG=True

# =============================================================================
# LOCAL CUDA / GPU DEVELOPMENT
# =============================================================================
# After installing the PyTorch CUDA build locally (see docs/technical/CUDA_SETUP.md):
#   uv pip install torch --index-url https://download.pytorch.org/whl/cu126 --force-reinstall
#
# Set UV_NO_SYNC=1 so that "uv run" does not resync and overwrite the CUDA build
# with the CPU build from the lock file. Leave unset in CI and on machines without
# an NVIDIA GPU.
#
# Note: uv run does NOT auto-load .env. To use this, either pass --env-file .env
# on every uv run, or set UV_ENV_FILE to this file's path. Alternatively, set
# UV_NO_SYNC=1 in your system/user environment variables (simpler for a CUDA dev PC).

# UV_NO_SYNC=1

# =============================================================================
# RETRIEVAL STRATEGY (Issue #79 - hybrid retrieval)
# =============================================================================
# Strategy: dense | sparse | hybrid
# - dense: semantic search only (default)
# - sparse: BM25 keyword search
# - hybrid: RRF merge of dense + sparse
# RETRIEVAL_STRATEGY=dense

# =============================================================================
# OLLAMA LLM CONFIGURATION (/api/ask endpoint)
# =============================================================================
# OLLAMA_MODEL must be a model available in Ollama. Default: mistral:7b
# If model not found, /api/ask returns 503 with remediation steps.
#
# To make a model available:
#   1. Start Ollama: ollama serve (or use Docker)
#   2. Pull the model: ollama pull mistral:7b
#   3. Or use an existing model: OLLAMA_MODEL=llama3.2:1b
#
# List available models: ollama list
# OLLAMA_MODEL=mistral:7b
# OLLAMA_BASE_URL=http://localhost:11434
