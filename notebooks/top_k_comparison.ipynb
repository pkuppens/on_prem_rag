{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Top-K Retrieval Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook compares retrieval performance for top 5, top 10, and top 50 results using semantic search embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup_notebook  # This fixes the path for imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "from rag_pipeline.config.parameter_sets import get_param_set\n",
    "from rag_pipeline.core.embeddings import process_pdf, query_embeddings\n",
    "from rag_pipeline.utils.directory_utils import get_project_root, get_test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths and parameters\n",
    "\n",
    "root = get_project_root()\n",
    "test_data = get_test_data_dir()\n",
    "param_name = \"fast\"\n",
    "params = get_param_set(param_name)\n",
    "pdf = test_data / \"2303.18223v16.pdf\"\n",
    "persist = root / \"data\" / f\"{param_name}_chroma\"\n",
    "\n",
    "# Ensure persist directory exists\n",
    "\n",
    "persist.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings if not already present\n",
    "if not (persist / \"chroma.sqlite3\").exists():\n",
    "    chunks, records = process_pdf(\n",
    "        pdf,\n",
    "        params.embedding.model_name,\n",
    "        persist_dir=str(persist),\n",
    "        chunk_size=params.chunking.chunk_size,\n",
    "        chunk_overlap=params.chunking.chunk_overlap,\n",
    "        max_pages=None,\n",
    "        deduplicate=True,\n",
    "    )\n",
    "    print(f\"Processing completed: {chunks} chunks, {records} records stored.\")\n",
    "else:\n",
    "    print(f\"Embeddings already exist in {persist}, skipping processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the embeddings\n",
    "\n",
    "query_text = \"Healthcare\"\n",
    "results = query_embeddings(query_text, params.embedding.model_name, persist_dir=str(persist), top_k=5)\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for top_k in [5, 10, 50]:\n",
    "    start = time.perf_counter()\n",
    "    results = query_embeddings(query_text, params.embedding.model_name, persist_dir=str(persist), top_k=top_k)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"Top {top_k} retrieval took {elapsed:.6f} seconds\")\n",
    "    print(f\"Found {len(results['all_results'])} results\")\n",
    "    if results[\"all_results\"]:\n",
    "        for i, result in enumerate(results[\"all_results\"]):\n",
    "            print(f\"\\nResult {i + 1}:\")\n",
    "            print(f\" Document: {result['document_name']}\")\n",
    "            print(f\" Chunk: {result['chunk_index']} (ID: {result['document_id']})\")\n",
    "            print(f\" Page: {result.get('page_number', 'unknown')}\")\n",
    "            print(f\" Similarity score: {result['similarity_score']:.4f}\")\n",
    "            print(f\" Text preview: {result['text'][:200]}...\")\n",
    "    else:\n",
    "        print(\"No results found for the query.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Check if the top 5 results are identical in both the top 5 and top 50 queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = query_embeddings(query_text, params.embedding.model_name, persist_dir=str(persist), top_k=5)\n",
    "top_50 = query_embeddings(query_text, params.embedding.model_name, persist_dir=str(persist), top_k=50)\n",
    "all_results_5 = top_5[\"all_results\"]\n",
    "top_5_all_results_50 = top_5[\"all_results\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_results_5) == len(top_5_all_results_50), \"The length of results should be the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare each result between top 5 and top 50 queries\n",
    "for i, (result_5, result_50) in enumerate(zip(all_results_5, top_5_all_results_50, strict=False)):\n",
    "    print(f\"\\nComparing result {i + 1}:\")\n",
    "    print(f\"Top 5 query - Document: {result_5['document_name']}, Score: {result_5['similarity_score']:.4f}\")\n",
    "    print(f\"Top 50 query - Document: {result_50['document_name']}, Score: {result_50['similarity_score']:.4f}\")\n",
    "\n",
    "    # Verify all fields match\n",
    "    assert result_5[\"document_name\"] == result_50[\"document_name\"], f\"Document names don't match for result {i + 1}\"\n",
    "    assert result_5[\"chunk_index\"] == result_50[\"chunk_index\"], f\"Chunk indices don't match for result {i + 1}\"\n",
    "    assert result_5[\"document_id\"] == result_50[\"document_id\"], f\"Document IDs don't match for result {i + 1}\"\n",
    "    assert abs(result_5[\"similarity_score\"] - result_50[\"similarity_score\"]) < 1e-6, (\n",
    "        f\"Similarity scores don't match for result {i + 1}\"\n",
    "    )\n",
    "    assert result_5[\"text\"] == result_50[\"text\"], f\"Text content doesn't match for result {i + 1}\"\n",
    "\n",
    "print(\"\\nAll top 5 results match between queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "This confirms that retrieving more results only adds minor overhead and the ranking of the first five remains the same."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
